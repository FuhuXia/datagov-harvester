"""New initial base migration

Revision ID: cf577d46fccd
Revises: 
Create Date: 2025-06-04 15:40:07.057986

"""
from alembic import op
import sqlalchemy as sa
from geoalchemy2 import Geometry


# revision identifiers, used by Alembic.
revision = 'cf577d46fccd'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('harvest_user',
    sa.Column('email', sa.String(length=120), nullable=False),
    sa.Column('name', sa.String(length=120), nullable=True),
    sa.Column('ssoid', sa.String(length=200), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('email'),
    sa.UniqueConstraint('ssoid')
    )

    # need to explicitly add postgis to be able to add a table with a Geometry column
    op.execute("CREATE EXTENSION IF NOT EXISTS postgis;")
    op.create_table('locations',
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('type', sa.String(), nullable=True),
    sa.Column('display_name', sa.String(), nullable=True),
    sa.Column('the_geom', Geometry(geometry_type='MULTIPOLYGON', from_text='ST_GeomFromEWKT', name='geometry'), nullable=True),
    sa.Column('type_order', sa.Integer(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )

    op.create_table('organization',
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('logo', sa.String(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('organization', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_organization_name'), ['name'], unique=False)

    op.create_table('harvest_source',
    sa.Column('organization_id', sa.String(length=36), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('url', sa.String(), nullable=False),
    sa.Column('notification_emails', sa.ARRAY(sa.String()), nullable=True),
    sa.Column('frequency', sa.Enum('manual', 'daily', 'weekly', 'biweekly', 'monthly', name='frequency'), nullable=False),
    sa.Column('schema_type', sa.Enum('iso19115_1', 'iso19115_2', 'csdgm', 'dcatus1.1: federal', 'dcatus1.1: non-federal', name='schema_type'), nullable=False),
    sa.Column('source_type', sa.Enum('document', 'waf', name='source_type'), nullable=False),
    sa.Column('notification_frequency', sa.Enum('on_error', 'always', name='notification_frequency'), nullable=False),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.ForeignKeyConstraint(['organization_id'], ['organization.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('url')
    )
    with op.batch_alter_table('harvest_source', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_harvest_source_frequency'), ['frequency'], unique=False)

    op.create_table('harvest_job',
    sa.Column('harvest_source_id', sa.String(length=36), nullable=False),
    sa.Column('status', sa.Enum('in_progress', 'complete', 'new', 'error', name='job_status'), nullable=False),
    sa.Column('job_type', sa.String(length=20), nullable=True),
    sa.Column('date_created', sa.DateTime(), nullable=True),
    sa.Column('date_finished', sa.DateTime(), nullable=True),
    sa.Column('records_total', sa.Integer(), nullable=True),
    sa.Column('records_added', sa.Integer(), nullable=True),
    sa.Column('records_updated', sa.Integer(), nullable=True),
    sa.Column('records_deleted', sa.Integer(), nullable=True),
    sa.Column('records_errored', sa.Integer(), nullable=True),
    sa.Column('records_ignored', sa.Integer(), nullable=True),
    sa.Column('records_validated', sa.Integer(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.ForeignKeyConstraint(['harvest_source_id'], ['harvest_source.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('harvest_job', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_harvest_job_date_created'), ['date_created'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_job_status'), ['status'], unique=False)

    op.create_table('harvest_job_error',
    sa.Column('harvest_job_id', sa.String(length=36), nullable=False),
    sa.Column('date_created', sa.DateTime(), nullable=True),
    sa.Column('type', sa.String(), nullable=True),
    sa.Column('message', sa.String(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.ForeignKeyConstraint(['harvest_job_id'], ['harvest_job.id'], ),
    sa.PrimaryKeyConstraint('id')
    )

    op.create_table('harvest_record',
    sa.Column('identifier', sa.String(), nullable=False),
    sa.Column('harvest_job_id', sa.String(length=36), nullable=False),
    sa.Column('harvest_source_id', sa.String(length=36), nullable=False),
    sa.Column('source_hash', sa.String(), nullable=True),
    sa.Column('source_raw', sa.String(), nullable=True),
    sa.Column('date_created', sa.DateTime(), nullable=True),
    sa.Column('date_finished', sa.DateTime(), nullable=True),
    sa.Column('ckan_id', sa.String(), nullable=True),
    sa.Column('ckan_name', sa.String(), nullable=True),
    sa.Column('action', sa.Enum('create', 'update', 'delete', name='record_action'), nullable=True),
    sa.Column('status', sa.Enum('error', 'success', name='record_status'), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.ForeignKeyConstraint(['harvest_job_id'], ['harvest_job.id'], ),
    sa.ForeignKeyConstraint(['harvest_source_id'], ['harvest_source.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('harvest_record', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_harvest_record_action'), ['action'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_record_ckan_id'), ['ckan_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_record_ckan_name'), ['ckan_name'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_record_date_created'), ['date_created'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_record_date_finished'), ['date_finished'], unique=False)
        batch_op.create_index(batch_op.f('ix_harvest_record_status'), ['status'], unique=False)

    op.create_table('harvest_record_error',
    sa.Column('harvest_record_id', sa.String(), nullable=True),
    sa.Column('harvest_job_id', sa.String(length=36), nullable=False),
    sa.Column('date_created', sa.DateTime(), nullable=True),
    sa.Column('type', sa.String(), nullable=True),
    sa.Column('message', sa.String(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.ForeignKeyConstraint(['harvest_job_id'], ['harvest_job.id'], ),
    sa.ForeignKeyConstraint(['harvest_record_id'], ['harvest_record.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('harvest_record_error')

    with op.batch_alter_table('harvest_record', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_harvest_record_status'))
        batch_op.drop_index(batch_op.f('ix_harvest_record_date_finished'))
        batch_op.drop_index(batch_op.f('ix_harvest_record_date_created'))
        batch_op.drop_index(batch_op.f('ix_harvest_record_ckan_name'))
        batch_op.drop_index(batch_op.f('ix_harvest_record_ckan_id'))
        batch_op.drop_index(batch_op.f('ix_harvest_record_action'))
    op.drop_table('harvest_record')

    op.drop_table('harvest_job_error')

    with op.batch_alter_table('harvest_job', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_harvest_job_status'))
        batch_op.drop_index(batch_op.f('ix_harvest_job_date_created'))
    op.drop_table('harvest_job')

    with op.batch_alter_table('harvest_source', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_harvest_source_frequency'))
    op.drop_table('harvest_source')

    with op.batch_alter_table('organization', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_organization_name'))
    op.drop_table('organization')

    op.drop_table('locations')
    op.execute("DROP EXTENSION IF EXISTS postgis_topology;")
    op.execute("DROP EXTENSION IF EXISTS postgis_tiger_geocoder;")
    op.execute("DROP EXTENSION IF EXISTS postgis;")

    op.drop_table('harvest_user')
    # ### end Alembic commands ###
